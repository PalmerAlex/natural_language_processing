{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Prior study (Codes in Week 5 folder）**: \n",
        "\n",
        "Please use this page as companion to understand the newsgroup data set.\n",
        "[Data Set](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
        "\n",
        "You will also need to be familiar with some text processing commands：\n",
        "\n",
        "[Tf-idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)\n",
        "\n",
        "[countvectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n"
      ],
      "metadata": {
        "id": "1ZVVMai8xRFX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhgYu18FM-_L"
      },
      "source": [
        "from IPython import get_ipython\n",
        "get_ipython().magic('reset -sf') "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXdrc29D71MH"
      },
      "source": [
        "# **Steps outline**\n",
        "1. Download your data set by inputting your student number.\n",
        "2. Process your text data, extract features, convert them into vectors\n",
        "3. Modeling, train models on the data set (select model, tune different parameters)\n",
        "4. Process your text data, extract features, convert them into vectors\n",
        "5. Analysis and discussions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "934uDa63sRnp"
      },
      "source": [
        "# Step 1: Load Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prior study (Codes in Week 5 folder）:\n",
        "\n",
        "Please use this page as companion to understand  [**Newsgroup data set**](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)\n",
        " "
      ],
      "metadata": {
        "id": "2k-V81t0z_NF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxDjTTcDrtVl"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train',  categories=categories, shuffle=True, random_state=42)\n",
        "twenty_test = fetch_20newsgroups(subset='test',  categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8VrHduYC-kd"
      },
      "source": [
        "**This is how to identify which data set to use (Please copy  the following information in report front   page).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvU6i2KNHzC4",
        "outputId": "0a13e6a0-39b7-40fa-a41e-9a9a77fc4684"
      },
      "source": [
        "index=input('type your student number?')\n",
        "x=divmod(int(index),4)\n",
        "yourdata1=x[1]\n",
        "y=divmod(int(index),3)\n",
        "yourdata2=y[1]\n",
        "\n",
        "print('This is your data set index ----> (', x[1], y[1], ')' )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type your student number?290156421\n",
            "This is your data set index ----> ( 1 0 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My student number is `29015642` but when inputting it gave me a data set index of (2 2) which gave me the same two categories. To prevent this issue, i added a `1` at the end of my student number and this gave me a different data set index."
      ],
      "metadata": {
        "id": "d8jT37dxQXKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code displays which categotries i will be using for my classification task."
      ],
      "metadata": {
        "id": "k8cFJUYJJlk9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXPpVRSGAPM7",
        "outputId": "ccd2f0dd-a3c3-4ba7-e557-03b565b80a69"
      },
      "source": [
        "data1= twenty_train.target_names[x[1]]\n",
        "data2= twenty_train.target_names[y[1]]\n",
        "categories1=[data1,data2]\n",
        "print(categories1)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['comp.graphics', 'alt.atheism']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNjBtO7-DOsu"
      },
      "source": [
        "**Your front page data information Ends here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1jAHpjtaSPu"
      },
      "source": [
        "# Step 2 Process your text data, extract features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El_vU9NocxVC"
      },
      "source": [
        "# 2.1 An example of preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDHwDyKzNirS"
      },
      "source": [
        "**An example is provided.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please pay attention  comment #replace ..., which means you need to change example text to your data set.\n",
        "Use google search for usages of  \"nltk tokenizer ”, \"nltk stemmer\", \"nltk pos tag\" to help your report writing."
      ],
      "metadata": {
        "id": "utJ6ap1bacK3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC3yT07PJnKp",
        "outputId": "77936bc8-2de2-45cc-8066-46b509396976"
      },
      "source": [
        "# write your own NLP precessing examples with  preprocessing techniques.\n",
        "print(twenty_train.target_names[1])\n",
        "data1=twenty_train.data[1]\n",
        "print(data1)\n",
        "# please   replace 1 in bracket to other data sample and explore the code\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        " "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n",
            "From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\n",
            "Subject: help: Splitting a trimming region along a mesh \n",
            "Organization: University Of Kentucky, Dept. of Math Sciences\n",
            "Lines: 28\n",
            "\n",
            "\n",
            "\n",
            "\tHi,\n",
            "\n",
            "\tI have a problem, I hope some of the 'gurus' can help me solve.\n",
            "\n",
            "\tBackground of the problem:\n",
            "\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \n",
            "\tmapping of a 3d Bezier patch into 2d. The area in this domain\n",
            "\twhich is inside a trimming loop had to be rendered. The trimming\n",
            "\tloop is a set of 2d Bezier curve segments.\n",
            "\tFor the sake of notation: the mesh is made up of cells.\n",
            "\n",
            "\tMy problem is this :\n",
            "\tThe trimming area has to be split up into individual smaller\n",
            "\tcells bounded by the trimming curve segments. If a cell\n",
            "\tis wholly inside the area...then it is output as a whole ,\n",
            "\telse it is trivially rejected. \n",
            "\n",
            "\tDoes any body know how thiss can be done, or is there any algo. \n",
            "\tsomewhere for doing this.\n",
            "\n",
            "\tAny help would be appreciated.\n",
            "\n",
            "\tThanks, \n",
            "\tAni.\n",
            "-- \n",
            "To get irritated is human, to stay cool, divine.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c275c93-d510-4dcc-8149-f385bf4bfe88",
        "id": "cRHBOWMnAAWA"
      },
      "source": [
        "# \n",
        "# tokenize: search: nltk tokenize \n",
        "example = \"This is an example sentence.\"\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "example_tokenize =word_tokenize(example)\n",
        "example_tokenize= word_tokenize(data1) # replace example in bracket to dataset.\n",
        "print(\"-------------------------tokenize:\")\n",
        "print(example_tokenize) \n",
        "print(\"Amount of tokens created:\",len(example_tokenize))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------tokenize:\n",
            "['From', ':', 'ani', '@', 'ms.uky.edu', '(', 'Aniruddha', 'B.', 'Deglurkar', ')', 'Subject', ':', 'help', ':', 'Splitting', 'a', 'trimming', 'region', 'along', 'a', 'mesh', 'Organization', ':', 'University', 'Of', 'Kentucky', ',', 'Dept', '.', 'of', 'Math', 'Sciences', 'Lines', ':', '28', 'Hi', ',', 'I', 'have', 'a', 'problem', ',', 'I', 'hope', 'some', 'of', 'the', \"'gurus\", \"'\", 'can', 'help', 'me', 'solve', '.', 'Background', 'of', 'the', 'problem', ':', 'I', 'have', 'a', 'rectangular', 'mesh', 'in', 'the', 'uv', 'domain', ',', 'i.e', 'the', 'mesh', 'is', 'a', 'mapping', 'of', 'a', '3d', 'Bezier', 'patch', 'into', '2d', '.', 'The', 'area', 'in', 'this', 'domain', 'which', 'is', 'inside', 'a', 'trimming', 'loop', 'had', 'to', 'be', 'rendered', '.', 'The', 'trimming', 'loop', 'is', 'a', 'set', 'of', '2d', 'Bezier', 'curve', 'segments', '.', 'For', 'the', 'sake', 'of', 'notation', ':', 'the', 'mesh', 'is', 'made', 'up', 'of', 'cells', '.', 'My', 'problem', 'is', 'this', ':', 'The', 'trimming', 'area', 'has', 'to', 'be', 'split', 'up', 'into', 'individual', 'smaller', 'cells', 'bounded', 'by', 'the', 'trimming', 'curve', 'segments', '.', 'If', 'a', 'cell', 'is', 'wholly', 'inside', 'the', 'area', '...', 'then', 'it', 'is', 'output', 'as', 'a', 'whole', ',', 'else', 'it', 'is', 'trivially', 'rejected', '.', 'Does', 'any', 'body', 'know', 'how', 'thiss', 'can', 'be', 'done', ',', 'or', 'is', 'there', 'any', 'algo', '.', 'somewhere', 'for', 'doing', 'this', '.', 'Any', 'help', 'would', 'be', 'appreciated', '.', 'Thanks', ',', 'Ani', '.', '--', 'To', 'get', 'irritated', 'is', 'human', ',', 'to', 'stay', 'cool', ',', 'divine', '.']\n",
            "Amount of tokens created: 216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea24523a-9322-4b8a-c16d-3934482ca7c5",
        "id": "kAaaP86_Ahmo"
      },
      "source": [
        "# stemmer: search: nltk stemmer  \n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "example_stem = stemmer.stem(data1)  # replace .....\n",
        "print(\"-------------------------stem:\")\n",
        "print(example_stem) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------stem:\n",
            "from: ani@ms.uky.edu (aniruddha b. deglurkar)\n",
            "subject: help: splitting a trimming region along a mesh \n",
            "organization: university of kentucky, dept. of math sciences\n",
            "lines: 28\n",
            "\n",
            "\n",
            "\n",
            "\thi,\n",
            "\n",
            "\ti have a problem, i hope some of the 'gurus' can help me solve.\n",
            "\n",
            "\tbackground of the problem:\n",
            "\ti have a rectangular mesh in the uv domain, i.e  the mesh is a \n",
            "\tmapping of a 3d bezier patch into 2d. the area in this domain\n",
            "\twhich is inside a trimming loop had to be rendered. the trimming\n",
            "\tloop is a set of 2d bezier curve segments.\n",
            "\tfor the sake of notation: the mesh is made up of cells.\n",
            "\n",
            "\tmy problem is this :\n",
            "\tthe trimming area has to be split up into individual smaller\n",
            "\tcells bounded by the trimming curve segments. if a cell\n",
            "\tis wholly inside the area...then it is output as a whole ,\n",
            "\telse it is trivially rejected. \n",
            "\n",
            "\tdoes any body know how thiss can be done, or is there any algo. \n",
            "\tsomewhere for doing this.\n",
            "\n",
            "\tany help would be appreciated.\n",
            "\n",
            "\tthanks, \n",
            "\tani.\n",
            "-- \n",
            "to get irritated is human, to stay cool, divine.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pos_taging: search: nltk pos tagging example\n",
        "example_posTag=nltk.pos_tag(example_tokenize)\n",
        "print(\"-------------------------pos_taging:\")\n",
        "print(example_posTag) "
      ],
      "metadata": {
        "id": "iL4Vr-m0ApLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0168946a-417b-4b9f-d27a-a828b7e20ad3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------pos_taging:\n",
            "[('From', 'IN'), (':', ':'), ('ani', 'NN'), ('@', 'NN'), ('ms.uky.edu', 'NN'), ('(', '('), ('Aniruddha', 'NNP'), ('B.', 'NNP'), ('Deglurkar', 'NNP'), (')', ')'), ('Subject', 'NN'), (':', ':'), ('help', 'NN'), (':', ':'), ('Splitting', 'VBG'), ('a', 'DT'), ('trimming', 'JJ'), ('region', 'NN'), ('along', 'IN'), ('a', 'DT'), ('mesh', 'JJ'), ('Organization', 'NN'), (':', ':'), ('University', 'NNP'), ('Of', 'IN'), ('Kentucky', 'NNP'), (',', ','), ('Dept', 'NNP'), ('.', '.'), ('of', 'IN'), ('Math', 'NNP'), ('Sciences', 'NNPS'), ('Lines', 'NNPS'), (':', ':'), ('28', 'CD'), ('Hi', 'NNP'), (',', ','), ('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('problem', 'NN'), (',', ','), ('I', 'PRP'), ('hope', 'VBP'), ('some', 'DT'), ('of', 'IN'), ('the', 'DT'), (\"'gurus\", 'NNP'), (\"'\", 'POS'), ('can', 'MD'), ('help', 'VB'), ('me', 'PRP'), ('solve', 'VB'), ('.', '.'), ('Background', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('problem', 'NN'), (':', ':'), ('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('rectangular', 'JJ'), ('mesh', 'NN'), ('in', 'IN'), ('the', 'DT'), ('uv', 'JJ'), ('domain', 'NN'), (',', ','), ('i.e', 'VBP'), ('the', 'DT'), ('mesh', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('mapping', 'NN'), ('of', 'IN'), ('a', 'DT'), ('3d', 'CD'), ('Bezier', 'NNP'), ('patch', 'NN'), ('into', 'IN'), ('2d', 'CD'), ('.', '.'), ('The', 'DT'), ('area', 'NN'), ('in', 'IN'), ('this', 'DT'), ('domain', 'NN'), ('which', 'WDT'), ('is', 'VBZ'), ('inside', 'IN'), ('a', 'DT'), ('trimming', 'NN'), ('loop', 'NN'), ('had', 'VBD'), ('to', 'TO'), ('be', 'VB'), ('rendered', 'VBN'), ('.', '.'), ('The', 'DT'), ('trimming', 'VBG'), ('loop', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('set', 'NN'), ('of', 'IN'), ('2d', 'CD'), ('Bezier', 'NNP'), ('curve', 'NN'), ('segments', 'NNS'), ('.', '.'), ('For', 'IN'), ('the', 'DT'), ('sake', 'NN'), ('of', 'IN'), ('notation', 'NN'), (':', ':'), ('the', 'DT'), ('mesh', 'NN'), ('is', 'VBZ'), ('made', 'VBN'), ('up', 'IN'), ('of', 'IN'), ('cells', 'NNS'), ('.', '.'), ('My', 'PRP$'), ('problem', 'NN'), ('is', 'VBZ'), ('this', 'DT'), (':', ':'), ('The', 'DT'), ('trimming', 'VBG'), ('area', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('be', 'VB'), ('split', 'VBN'), ('up', 'RP'), ('into', 'IN'), ('individual', 'JJ'), ('smaller', 'JJR'), ('cells', 'NNS'), ('bounded', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('trimming', 'VBG'), ('curve', 'NN'), ('segments', 'NNS'), ('.', '.'), ('If', 'IN'), ('a', 'DT'), ('cell', 'NN'), ('is', 'VBZ'), ('wholly', 'RB'), ('inside', 'IN'), ('the', 'DT'), ('area', 'NN'), ('...', ':'), ('then', 'RB'), ('it', 'PRP'), ('is', 'VBZ'), ('output', 'NN'), ('as', 'IN'), ('a', 'DT'), ('whole', 'NN'), (',', ','), ('else', 'VB'), ('it', 'PRP'), ('is', 'VBZ'), ('trivially', 'RB'), ('rejected', 'VBN'), ('.', '.'), ('Does', 'VBZ'), ('any', 'DT'), ('body', 'NN'), ('know', 'VB'), ('how', 'WRB'), ('thiss', 'JJ'), ('can', 'MD'), ('be', 'VB'), ('done', 'VBN'), (',', ','), ('or', 'CC'), ('is', 'VBZ'), ('there', 'RB'), ('any', 'DT'), ('algo', 'NN'), ('.', '.'), ('somewhere', 'RB'), ('for', 'IN'), ('doing', 'VBG'), ('this', 'DT'), ('.', '.'), ('Any', 'DT'), ('help', 'NN'), ('would', 'MD'), ('be', 'VB'), ('appreciated', 'VBN'), ('.', '.'), ('Thanks', 'NNS'), (',', ','), ('Ani', 'NNP'), ('.', '.'), ('--', ':'), ('To', 'TO'), ('get', 'VB'), ('irritated', 'JJ'), ('is', 'VBZ'), ('human', 'JJ'), (',', ','), ('to', 'TO'), ('stay', 'VB'), ('cool', 'JJ'), (',', ','), ('divine', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-n6AAbc_-_5"
      },
      "source": [
        " # consituency parsing, chunking\n",
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(example_posTag)\n",
        "print(result) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7VpnVNpKuUt"
      },
      "source": [
        "#2.2 NLP Preprocesssing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmXyhqwOaUQ"
      },
      "source": [
        "**Some preprocessing are provided for convenience. Please include why NLP preprocessing is in your report. Explain what techniques have been experimented in your report.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8u5y9adK3tc",
        "outputId": "b1a54d38-c17c-4695-b05a-acad1131cf59"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "stopwordEn = stopwords.words('english')\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "\n",
        "def lemmaWord(word):\n",
        "    lemma = wordnet.morphy(word)\n",
        "    if lemma is not None:\n",
        "        return lemma\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "def stemWord(word):\n",
        "    stem = stemmer.stem(word)\n",
        "    if stem is not None:\n",
        "        return stem\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "def processText(text,lemma=False, gram=1, rmStop=True): # default remove stop words\n",
        "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b|@\\w+|#', '', text, flags=re.MULTILINE) #delete URL, #hashtag# , and @xxx\n",
        "    tokens = word_tokenize(text)\n",
        "    whitelist = [\"n't\", \"not\", \"no\"]\n",
        "    new_tokens = []\n",
        "    stoplist = stopwordEn if rmStop else []\n",
        "    for i in tokens:\n",
        "      i = i.lower()\n",
        "      if i.isalpha() and (i not in stoplist or i in whitelist):  #i not in ['.',',',';']  and (...)\n",
        "        if lemma: i = lemmaWord(i)\n",
        "        new_tokens.append(i)\n",
        "    del tokens\n",
        "\n",
        "    #tokens = [lemmaWord(i.lower()) if lemma else i.lower() for i in tokens if (i.lower() not in stoplist or i.lower() in whitelist) and i.isalpha()]\n",
        "    if gram<=1:\n",
        "        return new_tokens\n",
        "    else:\n",
        "        return [' '.join(i) for i in nltk.ngrams(new_tokens, gram)]\n",
        "\n",
        "       "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKFoZaWSVrnq"
      },
      "source": [
        "def getTags(text):\n",
        "  token = word_tokenize(text)\n",
        "  token = [l.lower() for l in token]\n",
        "  train_tags = nltk.pos_tag(token)\n",
        "  return [i[1] for i in train_tags]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAq22sCUPvZn",
        "outputId": "13abd07d-6683-468c-f06d-ad3954ec265a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\n",
            "Subject: help: Splitting a trimming region along a mesh \n",
            "Organization: University Of Kentucky, Dept. of Math Sciences\n",
            "Lines: 28\n",
            "\n",
            "\n",
            "\n",
            "\tHi,\n",
            "\n",
            "\tI have a problem, I hope some of the 'gurus' can help me solve.\n",
            "\n",
            "\tBackground of the problem:\n",
            "\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \n",
            "\tmapping of a 3d Bezier patch into 2d. The area in this domain\n",
            "\twhich is inside a trimming loop had to be rendered. The trimming\n",
            "\tloop is a set of 2d Bezier curve segments.\n",
            "\tFor the sake of notation: the mesh is made up of cells.\n",
            "\n",
            "\tMy problem is this :\n",
            "\tThe trimming area has to be split up into individual smaller\n",
            "\tcells bounded by the trimming curve segments. If a cell\n",
            "\tis wholly inside the area...then it is output as a whole ,\n",
            "\telse it is trivially rejected. \n",
            "\n",
            "\tDoes any body know how thiss can be done, or is there any algo. \n",
            "\tsomewhere for doing this.\n",
            "\n",
            "\tAny help would be appreciated.\n",
            "\n",
            "\tThanks, \n",
            "\tAni.\n",
            "-- \n",
            "To get irritated is human, to stay cool, divine.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8mwYOcFcS02",
        "outputId": "85078457-46e1-42c3-f4cc-2f5029ae67e9"
      },
      "source": [
        "print(getTags(data1))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IN', ':', 'NN', 'NN', 'NN', '(', 'JJ', 'NN', 'NN', ')', 'NN', ':', 'NN', ':', 'VBG', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', ':', 'NN', 'IN', 'NN', ',', 'NN', '.', 'IN', 'NN', 'NNS', 'NNS', ':', 'CD', 'NN', ',', 'NN', 'VBP', 'DT', 'NN', ',', 'NN', 'VBP', 'DT', 'IN', 'DT', 'NNP', 'POS', 'MD', 'VB', 'PRP', 'VB', '.', 'NN', 'IN', 'DT', 'NN', ':', 'NN', 'VBP', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', ',', 'VBP', 'DT', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'DT', 'CD', 'NN', 'NN', 'IN', 'CD', '.', 'DT', 'NN', 'IN', 'DT', 'NN', 'WDT', 'VBZ', 'IN', 'DT', 'NN', 'NN', 'VBD', 'TO', 'VB', 'VBN', '.', 'DT', 'VBG', 'NN', 'VBZ', 'DT', 'NN', 'IN', 'CD', 'NN', 'NN', 'NNS', '.', 'IN', 'DT', 'NN', 'IN', 'NN', ':', 'DT', 'NN', 'VBZ', 'VBN', 'IN', 'IN', 'NNS', '.', 'PRP$', 'NN', 'VBZ', 'DT', ':', 'DT', 'VBG', 'NN', 'VBZ', 'TO', 'VB', 'VBN', 'RP', 'IN', 'JJ', 'JJR', 'NNS', 'VBN', 'IN', 'DT', 'VBG', 'NN', 'NNS', '.', 'IN', 'DT', 'NN', 'VBZ', 'RB', 'IN', 'DT', 'NN', ':', 'RB', 'PRP', 'VBZ', 'NN', 'IN', 'DT', 'NN', ',', 'VB', 'PRP', 'VBZ', 'RB', 'VBN', '.', 'VBZ', 'DT', 'NN', 'VB', 'WRB', 'JJ', 'MD', 'VB', 'VBN', ',', 'CC', 'VBZ', 'RB', 'DT', 'NN', '.', 'RB', 'IN', 'VBG', 'DT', '.', 'DT', 'NN', 'MD', 'VB', 'VBN', '.', 'NNS', ',', 'NN', '.', ':', 'TO', 'VB', 'JJ', 'VBZ', 'JJ', ',', 'TO', 'VB', 'JJ', ',', 'NN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "-ZRqySa8cbr1",
        "outputId": "7a6d9811-f624-44b1-d2fc-07a584375f07"
      },
      "source": [
        "print(getTags(dataset))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-33011aebd553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetTags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(processText(data1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-11NhAOk_MCt",
        "outputId": "fe3ef847-6819-4e04-d426-e7aafb253b26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aniruddha', 'deglurkar', 'subject', 'help', 'splitting', 'trimming', 'region', 'along', 'mesh', 'organization', 'university', 'kentucky', 'dept', 'math', 'sciences', 'lines', 'hi', 'problem', 'hope', 'help', 'solve', 'background', 'problem', 'rectangular', 'mesh', 'uv', 'domain', 'mesh', 'mapping', 'bezier', 'patch', 'area', 'domain', 'inside', 'trimming', 'loop', 'rendered', 'trimming', 'loop', 'set', 'bezier', 'curve', 'segments', 'sake', 'notation', 'mesh', 'made', 'cells', 'problem', 'trimming', 'area', 'split', 'individual', 'smaller', 'cells', 'bounded', 'trimming', 'curve', 'segments', 'cell', 'wholly', 'inside', 'area', 'output', 'whole', 'else', 'trivially', 'rejected', 'body', 'know', 'thiss', 'done', 'algo', 'somewhere', 'help', 'would', 'appreciated', 'thanks', 'ani', 'get', 'irritated', 'human', 'stay', 'cool', 'divine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44xTvpLa_UC9"
      },
      "source": [
        "# Step 3: Build a Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g5g93owSogu"
      },
      "source": [
        "**Modify the block code below to your choice of classifier [link text](https://www.nltk.org/book/ch06.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGs1A8S1TMTi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9HMKvgGMHPB",
        "outputId": "0295864d-966d-4fea-ea97-4a000639c4a4"
      },
      "source": [
        "print(categories1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['comp.graphics', 'alt.atheism']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without modification, the code will output all four classes. \n",
        "\n",
        "\n",
        "I included some commented codes in places where you may use to change to two class data sets   from your student number, and use logistic model.\n",
        "Your data sets can be obtained as twenty_train1, twenty_test1. All  data set names can be adjusted to get it right."
      ],
      "metadata": {
        "id": "Yl4relrvUjHt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PDFkEEiL1GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd5e6bc-b24b-4883-e61a-9fcc36773448"
      },
      "source": [
        "twenty_train1 = fetch_20newsgroups(subset='train',  categories=categories1, shuffle=True, random_state=42)\n",
        "twenty_test1 = fetch_20newsgroups(subset='test',  categories=categories1, shuffle=True, random_state=42)\n",
        "for name in twenty_test1.target_names:\n",
        "  print(name)\n",
        "print(twenty_test1.target_names[0])\n",
        "print(len(twenty_test1.data))\n",
        "print(len(twenty_train1.data))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism\n",
            "comp.graphics\n",
            "alt.atheism\n",
            "708\n",
            "1064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train1 = fetch_20newsgroups(subset='train', categories=categories1, shuffle=True, random_state=42)\n",
        "twenty_test1 = fetch_20newsgroups(subset='test', categories=categories1, shuffle=True, random_state=42)\n",
        "\n",
        "# Count the number of instances for each class in the training set\n",
        "train_class_counts = {}\n",
        "for label in twenty_train1.target:\n",
        "    if label not in train_class_counts:\n",
        "        train_class_counts[label] = 0\n",
        "    train_class_counts[label] += 1\n",
        "\n",
        "# Count the number of instances for each class in the test set\n",
        "test_class_counts = {}\n",
        "for label in twenty_test1.target:\n",
        "    if label not in test_class_counts:\n",
        "        test_class_counts[label] = 0\n",
        "    test_class_counts[label] += 1\n",
        "\n",
        "# Print the class counts\n",
        "print(\"Training set class counts:\")\n",
        "for label, count in train_class_counts.items():\n",
        "    print(f\"{twenty_train1.target_names[label]}: {count}\")\n",
        "    \n",
        "print(\"\\nTest set class counts:\")\n",
        "for label, count in test_class_counts.items():\n",
        "    print(f\"{twenty_test1.target_names[label]}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7epYv2zyucOr",
        "outputId": "be10bfe4-3c07-4c08-823d-1faa9d7e7a07"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set class counts:\n",
            "alt.atheism: 480\n",
            "comp.graphics: 584\n",
            "\n",
            "Test set class counts:\n",
            "alt.atheism: 319\n",
            "comp.graphics: 389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNm3axlhdzlF"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "text_clf = Pipeline([          \n",
        "    ('vect', CountVectorizer(binary=True,analyzer=processText)), \n",
        "    #('vect', CountVectorizer(binary=False,analyzer=processText))\n",
        "    #('vect', CountVectorizer(binary=True,analyzer=getTags))\n",
        "    #('vect', CountVectorizer(binary=False,analyzer=getTags)) #preprocessing task\n",
        "    #('tfidf', TfidfTransformer(use_idf=True)), #feature extraction\n",
        "    \n",
        "    ('clf', SGDClassifier())\n",
        "    # ('clf', LogisticRegression())\n",
        "\n",
        "])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "# Level: lexicon, model: tf-idf\n",
        "text_clf = Pipeline([\n",
        "    # add your code about text processing           \n",
        "    ('vect', CountVectorizer(binary=True,analyzer=processText)),  #preprocessing task\n",
        "    ('tfidf', TfidfTransformer(use_idf=True)), #feature extraction\n",
        "\n",
        "    # change your classifier here, search: sklearn logistic regression example\n",
        "    ('clf', SGDClassifier())\n",
        "    # ('clf', LogisticRegression())\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "tNIACdIblAIB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(twenty_train1.data, twenty_train1.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "fqEJqmqes2YW",
        "outputId": "b001d8d8-c86a-4893-cb1b-e7db36d680b6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect',\n",
              "                 CountVectorizer(analyzer=<function processText at 0x7ff663d6d280>,\n",
              "                                 binary=True)),\n",
              "                ('tfidf', TfidfTransformer()), ('clf', SGDClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                 CountVectorizer(analyzer=&lt;function processText at 0x7ff663d6d280&gt;,\n",
              "                                 binary=True)),\n",
              "                (&#x27;tfidf&#x27;, TfidfTransformer()), (&#x27;clf&#x27;, SGDClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                 CountVectorizer(analyzer=&lt;function processText at 0x7ff663d6d280&gt;,\n",
              "                                 binary=True)),\n",
              "                (&#x27;tfidf&#x27;, TfidfTransformer()), (&#x27;clf&#x27;, SGDClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&lt;function processText at 0x7ff663d6d280&gt;, binary=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Vuq37Bf3Qjpn",
        "outputId": "5027dd2c-d326-463d-a84b-e100cb84fc3e"
      },
      "source": [
        "\n",
        " # To make prediction with dev/test set\n",
        "predicted = text_clf.predict(twenty_test1.data)\n",
        "# To evaluate your prediction on dev set\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\", metrics.accuracy_score(twenty_test1.target, predicted))\n",
        "\n",
        "print(metrics.classification_report(twenty_test1.target, predicted, target_names=twenty_test1.target_names))\n",
        "\n",
        "# confusion class\n",
        "pd.DataFrame(metrics.confusion_matrix(twenty_test1.target, predicted),\n",
        "             columns=twenty_test1.target_names,index=twenty_test1.target_names)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9788135593220338\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  alt.atheism       0.98      0.97      0.98       319\n",
            "comp.graphics       0.98      0.98      0.98       389\n",
            "\n",
            "     accuracy                           0.98       708\n",
            "    macro avg       0.98      0.98      0.98       708\n",
            " weighted avg       0.98      0.98      0.98       708\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               alt.atheism  comp.graphics\n",
              "alt.atheism            311              8\n",
              "comp.graphics            7            382"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdacc57c-ee1d-4625-a4c6-71971c70dd4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt.atheism</th>\n",
              "      <th>comp.graphics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt.atheism</th>\n",
              "      <td>311</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.graphics</th>\n",
              "      <td>7</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdacc57c-ee1d-4625-a4c6-71971c70dd4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdacc57c-ee1d-4625-a4c6-71971c70dd4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdacc57c-ee1d-4625-a4c6-71971c70dd4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Values and labels\n",
        "values = [0.959, 0.951, 0.733, 0.811, 0.979, 0.962, 0.743, 0.785]\n",
        "labels = ['Iteration 1', 'Iteration 2', 'Iteration 3', 'Iteration 4', 'Iteration 5', 'Iteration 6', 'Iteration 7', 'Iteration 8']\n",
        "\n",
        "# Plot the bar chart\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "bars = ax.bar(labels, values, color='b')\n",
        "\n",
        "# Add labels to each bar\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 3),  # 3 points vertical offset\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "# Highlight the best and second best bars\n",
        "max_value = max(values)\n",
        "second_max_value = sorted(values, reverse=True)[1]\n",
        "for i, bar in enumerate(bars):\n",
        "    if bar.get_height() == max_value:\n",
        "        bar.set_color('g')  # Highlight the best bar with green\n",
        "    elif bar.get_height() == second_max_value:\n",
        "        bar.set_color('y')  # Highlight the second best bar with yellow\n",
        "\n",
        "ax.set_xlabel('Model Itteration')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Model Performance Bar chart')\n",
        "ax.tick_params(axis='y', labelrotation=-90, labelsize=8)\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jjl_F9ssVqjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjQ8DmPNRUuJ"
      },
      "source": [
        "# Step 4: Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMdoIHjMRWce"
      },
      "source": [
        "# To make prediction with dev/test set\n",
        "predicted = text_clf.predict(twenty_test1.data)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GXHJHqoBmyJ"
      },
      "source": [
        "# Step 5: Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You need to modify the code so only two classes from your student number are output as matrix.**"
      ],
      "metadata": {
        "id": "QuBuHl6G5xhN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "LdB9js0QDErf",
        "outputId": "3c2acd83-6420-42f8-bf62-9978a2fb198e"
      },
      "source": [
        "# To evaluate your prediction on dev set\n",
        "from sklearn import metrics\n",
        "print(\"Accuracy:\", metrics.accuracy_score(twenty_test1.target, predicted))\n",
        "\n",
        "print(metrics.classification_report(twenty_test1.target, predicted, target_names=twenty_test1.target_names))\n",
        "\n",
        "# confusion class\n",
        "pd.DataFrame(metrics.confusion_matrix(twenty_test1.target, predicted),\n",
        "             columns=twenty_test1.target_names,index=twenty_test1.target_names)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9788135593220338\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  alt.atheism       0.98      0.97      0.98       319\n",
            "comp.graphics       0.98      0.98      0.98       389\n",
            "\n",
            "     accuracy                           0.98       708\n",
            "    macro avg       0.98      0.98      0.98       708\n",
            " weighted avg       0.98      0.98      0.98       708\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               alt.atheism  comp.graphics\n",
              "alt.atheism            311              8\n",
              "comp.graphics            7            382"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53866dbe-3551-40d1-907f-82f0998dc3b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt.atheism</th>\n",
              "      <th>comp.graphics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt.atheism</th>\n",
              "      <td>311</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.graphics</th>\n",
              "      <td>7</td>\n",
              "      <td>382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53866dbe-3551-40d1-907f-82f0998dc3b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53866dbe-3551-40d1-907f-82f0998dc3b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53866dbe-3551-40d1-907f-82f0998dc3b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCLCqFXPQsRq"
      },
      "source": [
        "# Step 6: Error Analysis and Discussion\n",
        "write down your own obseration about the predictions. Consider both confusion matrix and selected examples. Which classes are predicted correctly or incorrecly, possible explaination, possible solutions \n",
        "\n",
        "Exmaple: 1) Lab Practical, which feature is helpful for female name classification. https://www.nltk.org/book/ch06.html \n",
        "2) research paper: https://github.com/yoonkim/CNN_sentence \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "kvBw9qkKDS-m",
        "outputId": "e8961e52-d571-46cf-99b5-f915ed646162"
      },
      "source": [
        "df_pred = pd.DataFrame({'news':twenty_test1.data,'prediction':predicted, 'true':twenty_test1.target})\n",
        "df_pred[df_pred['true'] != df_pred['prediction']]\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  news  prediction  true\n",
              "33   From: pdudey@willamette.edu (The Lisp SubGuru)...           0     1\n",
              "95   From: johnchad@triton.unm.edu (jchadwic)\\nSubj...           1     0\n",
              "109  From: gck@aero.org (Gregory C. Kozlowski)\\nSub...           1     0\n",
              "145  From: pstlb@aurora.alaska.edu\\nSubject: Where ...           0     1\n",
              "173  From: val@fcom.cc.utah.edu (Val Kartchner)\\nSu...           0     1\n",
              "177  From: mccullou@snake2.cs.wisc.edu (Mark McCull...           1     0\n",
              "188  From: jackson@sandman.ece.clarkson.edu (Peter ...           0     1\n",
              "199  From: sjs28257@uxa.cso.uiuc.edu (Steve Stelter...           1     0\n",
              "213  From: cstxqbe@dcs.warwick.ac.uk (Kate Kingman)...           0     1\n",
              "514  From: christen@astro.ocis.temple.edu (Carl Chr...           1     0\n",
              "519  From: scharle@lukasiewicz.cc.nd.edu (scharle)\\...           1     0\n",
              "610  From: kyle@wam.umd.edu (Kyle Xavier Hourihan)\\...           0     1\n",
              "613  From: christen@astro.ocis.temple.edu (Carl Chr...           1     0\n",
              "660  From: kadie@cs.uiuc.edu (Carl M Kadie)\\nSubjec...           1     0\n",
              "693  From: jk87377@lehtori.cc.tut.fi (Kouhia Juhana...           0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91399c70-8abd-463d-9e38-b5539627615c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news</th>\n",
              "      <th>prediction</th>\n",
              "      <th>true</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>From: pdudey@willamette.edu (The Lisp SubGuru)...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>From: johnchad@triton.unm.edu (jchadwic)\\nSubj...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>From: gck@aero.org (Gregory C. Kozlowski)\\nSub...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>From: pstlb@aurora.alaska.edu\\nSubject: Where ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>From: val@fcom.cc.utah.edu (Val Kartchner)\\nSu...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>From: mccullou@snake2.cs.wisc.edu (Mark McCull...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>From: jackson@sandman.ece.clarkson.edu (Peter ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>From: sjs28257@uxa.cso.uiuc.edu (Steve Stelter...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>From: cstxqbe@dcs.warwick.ac.uk (Kate Kingman)...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>From: christen@astro.ocis.temple.edu (Carl Chr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>From: scharle@lukasiewicz.cc.nd.edu (scharle)\\...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>From: kyle@wam.umd.edu (Kyle Xavier Hourihan)\\...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>From: christen@astro.ocis.temple.edu (Carl Chr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>From: kadie@cs.uiuc.edu (Carl M Kadie)\\nSubjec...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>From: jk87377@lehtori.cc.tut.fi (Kouhia Juhana...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91399c70-8abd-463d-9e38-b5539627615c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91399c70-8abd-463d-9e38-b5539627615c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91399c70-8abd-463d-9e38-b5539627615c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(twenty_test1.target[95])\n",
        "print(twenty_test1.data[95])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p04S2D9QtbTP",
        "outputId": "1ef5ab47-2313-48a4-9005-0aa437b93ccd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "From: johnchad@triton.unm.edu (jchadwic)\n",
            "Subject: Another request for Darwin Fish\n",
            "Organization: University of New Mexico, Albuquerque\n",
            "Lines: 11\n",
            "NNTP-Posting-Host: triton.unm.edu\n",
            "\n",
            "Hello Gang,\n",
            "\n",
            "There have been some notes recently asking where to obtain the DARWIN fish.\n",
            "This is the same question I have and I have not seen an answer on the\n",
            "net. If anyone has a contact please post on the net or email me.\n",
            "\n",
            "Thanks,\n",
            "\n",
            "john chadwick\n",
            "johnchad@triton.unm.edu\n",
            "or\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRIRg2rufjPu"
      },
      "source": [
        "#References:  \n",
        "\n",
        "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html \n",
        "\n",
        "https://www.nltk.org/book/ch06.html \n",
        "\n",
        "search: Other online resources: \n",
        "\n",
        "https://towardsdatascience.com/setting-up-text-preprocessing-pipeline-using-scikit-learn-and-spacy-e09b9b76758f \n",
        " \n",
        "sentiment analysis scikit learn \n",
        "\n",
        "scikit learn or nltk + NLP techniques \n",
        "\n",
        "python + NLP techniques\n",
        "\n",
        "scikit learn logistic regression\n",
        "\n",
        "\n"
      ]
    }
  ]
}